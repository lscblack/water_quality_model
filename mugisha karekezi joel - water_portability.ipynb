{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6010f5dc-f8cd-43a5-970f-934e5a348759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " ph                 491\n",
      "Hardness             0\n",
      "Solids               0\n",
      "Chloramines          0\n",
      "Sulfate            781\n",
      "Conductivity         0\n",
      "Organic_carbon       0\n",
      "Trihalomethanes    162\n",
      "Turbidity            0\n",
      "Potability           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Load the data\n",
    "df = pd.read_csv(\"water_potability.csv\")\n",
    "\n",
    "# 2. Inspect missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# 3. Handle missing values with (mean imputation)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "# 5. Split features and target x,y\n",
    "X = df_imputed.drop(\"Potability\", axis=1)\n",
    "y = df_imputed[\"Potability\"]\n",
    "\n",
    "# 6. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 7. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029efb80-4941-423f-ae55-51b301fdb3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5556 - loss: 0.8615 - val_accuracy: 0.6317 - val_loss: 0.8214\n",
      "Epoch 2/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6142 - loss: 0.8245 - val_accuracy: 0.6489 - val_loss: 0.8010\n",
      "Epoch 3/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6174 - loss: 0.8062 - val_accuracy: 0.6355 - val_loss: 0.7870\n",
      "Epoch 4/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6566 - loss: 0.7673 - val_accuracy: 0.6508 - val_loss: 0.7660\n",
      "Epoch 5/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6523 - loss: 0.7577 - val_accuracy: 0.6489 - val_loss: 0.7578\n",
      "Epoch 6/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6733 - loss: 0.7450 - val_accuracy: 0.6469 - val_loss: 0.7444\n",
      "Epoch 7/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6861 - loss: 0.7297 - val_accuracy: 0.6412 - val_loss: 0.7328\n",
      "Epoch 8/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6679 - loss: 0.7105 - val_accuracy: 0.6374 - val_loss: 0.7295\n",
      "Epoch 9/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 0.7183 - val_accuracy: 0.6412 - val_loss: 0.7256\n",
      "Epoch 10/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6757 - loss: 0.7032 - val_accuracy: 0.6489 - val_loss: 0.7136\n",
      "Epoch 11/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6887 - loss: 0.6958 - val_accuracy: 0.6450 - val_loss: 0.7124\n",
      "Epoch 12/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.6709 - val_accuracy: 0.6450 - val_loss: 0.7061\n",
      "Epoch 13/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.6918 - val_accuracy: 0.6317 - val_loss: 0.7090\n",
      "Epoch 14/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6857 - loss: 0.6757 - val_accuracy: 0.6412 - val_loss: 0.7021\n",
      "Epoch 15/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6793 - loss: 0.6817 - val_accuracy: 0.6450 - val_loss: 0.7003\n",
      "Epoch 16/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6997 - loss: 0.6607 - val_accuracy: 0.6431 - val_loss: 0.6985\n",
      "Epoch 17/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6845 - loss: 0.6679 - val_accuracy: 0.6508 - val_loss: 0.6950\n",
      "Epoch 18/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6596 - loss: 0.6811 - val_accuracy: 0.6298 - val_loss: 0.6873\n",
      "Epoch 19/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6658 - loss: 0.6729 - val_accuracy: 0.6469 - val_loss: 0.6824\n",
      "Epoch 20/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6881 - loss: 0.6555 - val_accuracy: 0.6374 - val_loss: 0.6869\n",
      "Epoch 21/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6982 - loss: 0.6454 - val_accuracy: 0.6450 - val_loss: 0.6864\n",
      "Epoch 22/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6857 - loss: 0.6539 - val_accuracy: 0.6240 - val_loss: 0.6767\n",
      "Epoch 23/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6887 - loss: 0.6500 - val_accuracy: 0.6489 - val_loss: 0.6794\n",
      "Epoch 24/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6924 - loss: 0.6349 - val_accuracy: 0.6450 - val_loss: 0.6764\n",
      "Epoch 25/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 0.6388 - val_accuracy: 0.6412 - val_loss: 0.6761\n",
      "Epoch 26/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6851 - loss: 0.6385 - val_accuracy: 0.6469 - val_loss: 0.6728\n",
      "Epoch 27/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.6508 - val_accuracy: 0.6374 - val_loss: 0.6773\n",
      "Epoch 28/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6999 - loss: 0.6223 - val_accuracy: 0.6412 - val_loss: 0.6740\n",
      "Epoch 29/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6957 - loss: 0.6282 - val_accuracy: 0.6431 - val_loss: 0.6711\n",
      "Epoch 30/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6885 - loss: 0.6375 - val_accuracy: 0.6336 - val_loss: 0.6717\n",
      "Epoch 31/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6922 - loss: 0.6209 - val_accuracy: 0.6317 - val_loss: 0.6710\n",
      "Epoch 32/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6966 - loss: 0.6215 - val_accuracy: 0.6374 - val_loss: 0.6716\n",
      "Epoch 33/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7007 - loss: 0.6193 - val_accuracy: 0.6450 - val_loss: 0.6728\n",
      "Epoch 34/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6894 - loss: 0.6347 - val_accuracy: 0.6393 - val_loss: 0.6664\n",
      "Epoch 35/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6792 - loss: 0.6335 - val_accuracy: 0.6412 - val_loss: 0.6705\n",
      "Epoch 36/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6937 - loss: 0.6243 - val_accuracy: 0.6374 - val_loss: 0.6683\n",
      "Epoch 37/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6922 - loss: 0.6101 - val_accuracy: 0.6355 - val_loss: 0.6646\n",
      "Epoch 38/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7040 - loss: 0.6205 - val_accuracy: 0.6317 - val_loss: 0.6710\n",
      "Epoch 39/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7028 - loss: 0.6298 - val_accuracy: 0.6317 - val_loss: 0.6667\n",
      "Epoch 40/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6812 - loss: 0.6353 - val_accuracy: 0.6317 - val_loss: 0.6632\n",
      "Epoch 41/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6966 - loss: 0.6169 - val_accuracy: 0.6279 - val_loss: 0.6661\n",
      "Epoch 42/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - loss: 0.6219 - val_accuracy: 0.6279 - val_loss: 0.6735\n",
      "Epoch 43/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6832 - loss: 0.6255 - val_accuracy: 0.6336 - val_loss: 0.6681\n",
      "Epoch 44/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.6289 - val_accuracy: 0.6317 - val_loss: 0.6664\n",
      "Epoch 45/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 0.6133 - val_accuracy: 0.6412 - val_loss: 0.6694\n",
      "Epoch 46/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7020 - loss: 0.6094 - val_accuracy: 0.6374 - val_loss: 0.6635\n",
      "Epoch 47/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6912 - loss: 0.6183 - val_accuracy: 0.6336 - val_loss: 0.6653\n",
      "Epoch 48/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6996 - loss: 0.6049 - val_accuracy: 0.6240 - val_loss: 0.6624\n",
      "Epoch 49/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6877 - loss: 0.6154 - val_accuracy: 0.6393 - val_loss: 0.6593\n",
      "Epoch 50/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6896 - loss: 0.6226 - val_accuracy: 0.6279 - val_loss: 0.6637\n",
      "Epoch 51/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6981 - loss: 0.6170 - val_accuracy: 0.6355 - val_loss: 0.6749\n",
      "Epoch 52/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6984 - loss: 0.6111 - val_accuracy: 0.6279 - val_loss: 0.6644\n",
      "Epoch 53/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6886 - loss: 0.6263 - val_accuracy: 0.6317 - val_loss: 0.6616\n",
      "Epoch 54/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7171 - loss: 0.6100 - val_accuracy: 0.6336 - val_loss: 0.6658\n",
      "Epoch 55/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7024 - loss: 0.6096 - val_accuracy: 0.6317 - val_loss: 0.6593\n",
      "Epoch 56/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6979 - loss: 0.6279 - val_accuracy: 0.6355 - val_loss: 0.6633\n",
      "Epoch 57/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6962 - loss: 0.6167 - val_accuracy: 0.6260 - val_loss: 0.6629\n",
      "Epoch 58/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6870 - loss: 0.6162 - val_accuracy: 0.6298 - val_loss: 0.6651\n",
      "Epoch 59/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7085 - loss: 0.6040 - val_accuracy: 0.6374 - val_loss: 0.6657\n",
      "Epoch 60/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7102 - loss: 0.6042 - val_accuracy: 0.6298 - val_loss: 0.6695\n",
      "Epoch 61/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 0.6234 - val_accuracy: 0.6279 - val_loss: 0.6643\n",
      "Epoch 62/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7155 - loss: 0.5991 - val_accuracy: 0.6240 - val_loss: 0.6597\n",
      "Epoch 63/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6029 - val_accuracy: 0.6336 - val_loss: 0.6659\n",
      "Epoch 64/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7068 - loss: 0.5976 - val_accuracy: 0.6298 - val_loss: 0.6694\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Accuracy: 0.7012\n",
      "F1 Score: 0.5172\n",
      "Precision: 0.7000\n",
      "Recall: 0.4102\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # <-- Add Input layer explicitly\n",
    "    Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-4, l2=1e-3)),\n",
    "    Dropout(0.3),  \n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-4, l2=1e-3)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.0008)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_classes = (y_pred_nn > 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_classes)\n",
    "f1 = f1_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes)\n",
    "recall = recall_score(y_test, y_pred_classes)\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4248d-72e7-4deb-b85f-9347ca39fc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
