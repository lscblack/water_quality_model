{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3NSLo6IzIY4"
   },
   "source": [
    "# Data Preprocessing Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4Ot0tCJgCtD",
    "outputId": "fe42aa30-ec68-4614-8de7-7d54b58d23e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " ph                 491\n",
      "Hardness             0\n",
      "Solids               0\n",
      "Chloramines          0\n",
      "Sulfate            781\n",
      "Conductivity         0\n",
      "Organic_carbon       0\n",
      "Trihalomethanes    162\n",
      "Turbidity            0\n",
      "Potability           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Load the data\n",
    "df = pd.read_csv(\"water_potability.csv\")\n",
    "\n",
    "# 2. Inspect missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# 3. Handle missing values with (mean imputation)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "\n",
    "# 5. Split features and target x,y\n",
    "X = df_imputed.drop(\"Potability\", axis=1)\n",
    "y = df_imputed[\"Potability\"]\n",
    "\n",
    "# 6. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 7. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nspbtsBqgkdU",
    "outputId": "49f64bbc-e1eb-4ed9-b361-28dc4bb4a7dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - accuracy: 0.5948 - loss: 0.7812 - val_accuracy: 0.6393 - val_loss: 0.7351\n",
      "Epoch 2/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6542 - loss: 0.7187 - val_accuracy: 0.6450 - val_loss: 0.7030\n",
      "Epoch 3/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6494 - loss: 0.7008 - val_accuracy: 0.6431 - val_loss: 0.6906\n",
      "Epoch 4/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6823 - loss: 0.6787 - val_accuracy: 0.6527 - val_loss: 0.6822\n",
      "Epoch 5/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6836 - loss: 0.6611 - val_accuracy: 0.6527 - val_loss: 0.6823\n",
      "Epoch 6/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6834 - loss: 0.6541 - val_accuracy: 0.6431 - val_loss: 0.6721\n",
      "Epoch 7/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6804 - loss: 0.6449 - val_accuracy: 0.6489 - val_loss: 0.6706\n",
      "Epoch 8/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7039 - loss: 0.6305 - val_accuracy: 0.6527 - val_loss: 0.6631\n",
      "Epoch 9/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6833 - loss: 0.6336 - val_accuracy: 0.6450 - val_loss: 0.6609\n",
      "Epoch 10/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6838 - loss: 0.6328 - val_accuracy: 0.6374 - val_loss: 0.6694\n",
      "Epoch 11/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7034 - loss: 0.6083 - val_accuracy: 0.6412 - val_loss: 0.6615\n",
      "Epoch 12/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.6252 - val_accuracy: 0.6336 - val_loss: 0.6719\n",
      "Epoch 13/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.6199 - val_accuracy: 0.6374 - val_loss: 0.6612\n",
      "Epoch 14/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6897 - loss: 0.6212 - val_accuracy: 0.6240 - val_loss: 0.6692\n",
      "Epoch 15/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.5950 - val_accuracy: 0.6279 - val_loss: 0.6622\n",
      "Epoch 16/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7003 - loss: 0.6163 - val_accuracy: 0.6527 - val_loss: 0.6539\n",
      "Epoch 17/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.5933 - val_accuracy: 0.6202 - val_loss: 0.6688\n",
      "Epoch 18/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7183 - loss: 0.5968 - val_accuracy: 0.6374 - val_loss: 0.6618\n",
      "Epoch 19/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.6142 - val_accuracy: 0.6374 - val_loss: 0.6568\n",
      "Epoch 20/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6984 - loss: 0.5987 - val_accuracy: 0.6336 - val_loss: 0.6546\n",
      "Epoch 21/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6922 - loss: 0.6047 - val_accuracy: 0.6279 - val_loss: 0.6572\n",
      "Epoch 22/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7019 - loss: 0.5921 - val_accuracy: 0.6336 - val_loss: 0.6666\n",
      "Epoch 23/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.5716 - val_accuracy: 0.6260 - val_loss: 0.6573\n",
      "Epoch 24/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7067 - loss: 0.5978 - val_accuracy: 0.6374 - val_loss: 0.6572\n",
      "Epoch 25/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.5943 - val_accuracy: 0.6298 - val_loss: 0.6558\n",
      "Epoch 26/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7082 - loss: 0.5971 - val_accuracy: 0.6298 - val_loss: 0.6607\n",
      "Epoch 27/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7149 - loss: 0.5934 - val_accuracy: 0.6298 - val_loss: 0.6535\n",
      "Epoch 28/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.5898 - val_accuracy: 0.6317 - val_loss: 0.6578\n",
      "Epoch 29/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.5795 - val_accuracy: 0.6317 - val_loss: 0.6557\n",
      "Epoch 30/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7105 - loss: 0.5885 - val_accuracy: 0.6412 - val_loss: 0.6648\n",
      "Epoch 31/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7286 - loss: 0.5720 - val_accuracy: 0.6298 - val_loss: 0.6642\n",
      "Epoch 32/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7136 - loss: 0.5819 - val_accuracy: 0.6260 - val_loss: 0.6579\n",
      "Epoch 33/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7220 - loss: 0.5726 - val_accuracy: 0.6164 - val_loss: 0.6706\n",
      "Epoch 34/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7223 - loss: 0.5699 - val_accuracy: 0.6279 - val_loss: 0.6589\n",
      "Epoch 35/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7082 - loss: 0.5857 - val_accuracy: 0.6298 - val_loss: 0.6703\n",
      "Epoch 36/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6915 - loss: 0.5927 - val_accuracy: 0.6374 - val_loss: 0.6599\n",
      "Epoch 37/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7393 - loss: 0.5663 - val_accuracy: 0.6355 - val_loss: 0.6588\n",
      "Epoch 38/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7079 - loss: 0.5836 - val_accuracy: 0.6374 - val_loss: 0.6599\n",
      "Epoch 39/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 0.5778 - val_accuracy: 0.6279 - val_loss: 0.6767\n",
      "Epoch 40/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7396 - loss: 0.5652 - val_accuracy: 0.6431 - val_loss: 0.6620\n",
      "Epoch 41/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7332 - loss: 0.5669 - val_accuracy: 0.6317 - val_loss: 0.6641\n",
      "Epoch 42/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7297 - loss: 0.5636 - val_accuracy: 0.6164 - val_loss: 0.6659\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Accuracy: 0.6829\n",
      "F1 Score: 0.5273\n",
      "Precision: 0.6304\n",
      "Recall: 0.4531\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.2),  \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(learning_rate=0.0015)\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5. Evaluate\n",
    "y_pred_nn = model.predict(X_test)\n",
    "y_pred_classes = (y_pred_nn > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_classes)\n",
    "f1 = f1_score(y_test, y_pred_classes)\n",
    "precision = precision_score(y_test, y_pred_classes)\n",
    "recall = recall_score(y_test, y_pred_classes)\n",
    "# summary viewer\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBjAADRAoROP"
   },
   "source": [
    "| Train Instance               | Engineer Name                     | Regularizer | Optimizer        | Early Stopping                   | Dropout Rate | Accuracy | F1 Score | Recall | Precision |\n",
    "| ---------------------------- | --------------------------------- | ----------- | ---------------- | -------------------------------- | ------------ | -------- | -------- | ------ | --------- |\n",
    "| water\\_potability\\_model\\_v3 | Loue Sauveur Christian (lscblack) | L2 (0.001)  | Adam (lr=0.0015) | Patience=15, monitor='val\\_loss' | 0.2          | 0.7027   | 0.5255   | 0.4219 | 0.6968   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "c_lHJfjyg9Vh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5761 - loss: 0.8653 - val_accuracy: 0.6088 - val_loss: 0.8316\n",
      "Epoch 2/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6259 - loss: 0.8109 - val_accuracy: 0.6298 - val_loss: 0.8054\n",
      "Epoch 3/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6268 - loss: 0.7933 - val_accuracy: 0.6374 - val_loss: 0.7843\n",
      "Epoch 4/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6471 - loss: 0.7698 - val_accuracy: 0.6603 - val_loss: 0.7679\n",
      "Epoch 5/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6519 - loss: 0.7559 - val_accuracy: 0.6527 - val_loss: 0.7553\n",
      "Epoch 6/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6591 - loss: 0.7393 - val_accuracy: 0.6489 - val_loss: 0.7415\n",
      "Epoch 7/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6745 - loss: 0.7208 - val_accuracy: 0.6565 - val_loss: 0.7329\n",
      "Epoch 8/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6835 - loss: 0.7113 - val_accuracy: 0.6355 - val_loss: 0.7248\n",
      "Epoch 9/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.6998 - val_accuracy: 0.6546 - val_loss: 0.7201\n",
      "Epoch 10/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6797 - loss: 0.7045 - val_accuracy: 0.6584 - val_loss: 0.7167\n",
      "Epoch 11/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6764 - loss: 0.7043 - val_accuracy: 0.6527 - val_loss: 0.7129\n",
      "Epoch 12/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6869 - loss: 0.6828 - val_accuracy: 0.6469 - val_loss: 0.7077\n",
      "Epoch 13/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6624 - loss: 0.6868 - val_accuracy: 0.6489 - val_loss: 0.7005\n",
      "Epoch 14/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6796 - loss: 0.6827 - val_accuracy: 0.6489 - val_loss: 0.6975\n",
      "Epoch 15/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 0.6756 - val_accuracy: 0.6431 - val_loss: 0.6955\n",
      "Epoch 16/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6918 - loss: 0.6631 - val_accuracy: 0.6469 - val_loss: 0.6942\n",
      "Epoch 17/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6803 - loss: 0.6662 - val_accuracy: 0.6412 - val_loss: 0.6913\n",
      "Epoch 18/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6898 - loss: 0.6666 - val_accuracy: 0.6412 - val_loss: 0.6883\n",
      "Epoch 19/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6895 - loss: 0.6615 - val_accuracy: 0.6336 - val_loss: 0.6898\n",
      "Epoch 20/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6974 - loss: 0.6393 - val_accuracy: 0.6221 - val_loss: 0.6891\n",
      "Epoch 21/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7002 - loss: 0.6394 - val_accuracy: 0.6374 - val_loss: 0.6800\n",
      "Epoch 22/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7023 - loss: 0.6498 - val_accuracy: 0.6317 - val_loss: 0.6793\n",
      "Epoch 23/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.6406 - val_accuracy: 0.6240 - val_loss: 0.6797\n",
      "Epoch 24/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7060 - loss: 0.6284 - val_accuracy: 0.6240 - val_loss: 0.6802\n",
      "Epoch 25/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6778 - loss: 0.6429 - val_accuracy: 0.6336 - val_loss: 0.6748\n",
      "Epoch 26/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6883 - loss: 0.6408 - val_accuracy: 0.6317 - val_loss: 0.6760\n",
      "Epoch 27/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7039 - loss: 0.6338 - val_accuracy: 0.6336 - val_loss: 0.6740\n",
      "Epoch 28/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6873 - loss: 0.6278 - val_accuracy: 0.6298 - val_loss: 0.6714\n",
      "Epoch 29/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6968 - loss: 0.6308 - val_accuracy: 0.6355 - val_loss: 0.6687\n",
      "Epoch 30/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.6413 - val_accuracy: 0.6412 - val_loss: 0.6676\n",
      "Epoch 31/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6870 - loss: 0.6453 - val_accuracy: 0.6336 - val_loss: 0.6674\n",
      "Epoch 32/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6875 - loss: 0.6318 - val_accuracy: 0.6279 - val_loss: 0.6691\n",
      "Epoch 33/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6973 - loss: 0.6250 - val_accuracy: 0.6260 - val_loss: 0.6692\n",
      "Epoch 34/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6998 - loss: 0.6194 - val_accuracy: 0.6260 - val_loss: 0.6677\n",
      "Epoch 35/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6851 - loss: 0.6282 - val_accuracy: 0.6317 - val_loss: 0.6690\n",
      "Epoch 36/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6891 - loss: 0.6337 - val_accuracy: 0.6355 - val_loss: 0.6701\n",
      "Epoch 37/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7073 - loss: 0.6089 - val_accuracy: 0.6221 - val_loss: 0.6632\n",
      "Epoch 38/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6839 - loss: 0.6299 - val_accuracy: 0.6298 - val_loss: 0.6600\n",
      "Epoch 39/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6913 - loss: 0.6191 - val_accuracy: 0.6374 - val_loss: 0.6629\n",
      "Epoch 40/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7051 - loss: 0.6158 - val_accuracy: 0.6240 - val_loss: 0.6680\n",
      "Epoch 41/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.6325 - val_accuracy: 0.6317 - val_loss: 0.6627\n",
      "Epoch 42/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7082 - loss: 0.6172 - val_accuracy: 0.6260 - val_loss: 0.6646\n",
      "Epoch 43/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7030 - loss: 0.6133 - val_accuracy: 0.6336 - val_loss: 0.6628\n",
      "Epoch 44/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7123 - loss: 0.6060 - val_accuracy: 0.6298 - val_loss: 0.6637\n",
      "Epoch 45/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6972 - loss: 0.6110 - val_accuracy: 0.6336 - val_loss: 0.6605\n",
      "Epoch 46/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6902 - loss: 0.6268 - val_accuracy: 0.6355 - val_loss: 0.6636\n",
      "Epoch 47/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7129 - loss: 0.6093 - val_accuracy: 0.6260 - val_loss: 0.6600\n",
      "Epoch 48/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6906 - loss: 0.6270 - val_accuracy: 0.6317 - val_loss: 0.6594\n",
      "Epoch 49/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7084 - loss: 0.6091 - val_accuracy: 0.6279 - val_loss: 0.6573\n",
      "Epoch 50/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6951 - loss: 0.6226 - val_accuracy: 0.6431 - val_loss: 0.6637\n",
      "Epoch 51/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.6091 - val_accuracy: 0.6145 - val_loss: 0.6632\n",
      "Epoch 52/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7122 - loss: 0.6007 - val_accuracy: 0.6336 - val_loss: 0.6640\n",
      "Epoch 53/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7018 - loss: 0.6112 - val_accuracy: 0.6164 - val_loss: 0.6689\n",
      "Epoch 54/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6821 - loss: 0.6199 - val_accuracy: 0.6260 - val_loss: 0.6661\n",
      "Epoch 55/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.5934 - val_accuracy: 0.6260 - val_loss: 0.6651\n",
      "Epoch 56/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7061 - loss: 0.6122 - val_accuracy: 0.6336 - val_loss: 0.6592\n",
      "Epoch 57/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7043 - loss: 0.6078 - val_accuracy: 0.6202 - val_loss: 0.6613\n",
      "Epoch 58/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7027 - loss: 0.6112 - val_accuracy: 0.6202 - val_loss: 0.6605\n",
      "Epoch 59/100\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7250 - loss: 0.5931 - val_accuracy: 0.6298 - val_loss: 0.6572\n",
      "Epoch 60/100\n",
      "\u001b[1m 1/66\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.6562 - loss: 0.6036"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # <-- Add Input layer explicitly\n",
    "    Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-4, l2=1e-3)),\n",
    "    Dropout(0.3),  \n",
    "    Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=1e-4, l2=1e-3)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.0008)\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
